{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теоретический материал – Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Персептрон представляет собой элементарную часть нейронной сети. Одиночный персептрон является линейным бинарным классификатором. В этой лекции мы рассмотрим процедуру обучения персептрона для классификации данных. Поскольку персептрон представляет собой бинарный классификатор, то мы будем рассматривать лишь два класса.\n",
    "\n",
    "Пусть мы рассматриваем некоторое множество (конечное или бесконечное) n-мерных векторов, которые будем обозначать  x=(x1,x2,...,xn)\n",
    "\n",
    "Будем считать, что это множество разбивается на два класса, которые мы будем обозначать +1 и -1. \n",
    "\n",
    "Поэтому возникает задача построения функции, которая задана на нашем множестве векторов, и принимает значения в множестве \n",
    "{+1, -1}. В качестве такой функции может выступать персептрон. С алгебраической точки зрения персептрон \n",
    "состоит из вектора весов w=(w0,w1,w2,...,wn).\n",
    "\n",
    "При этом персептрон работает по формуле\n",
    "\n",
    "y=sign(w0 + x1w1 + x2w2 + ... + xnwn),\n",
    "\n",
    "где функция sign(t) равна +1, если t ≥ 0, и равна -1, если t < 0.\n",
    "\n",
    "Приведем алгоритм обучения персептрона. Пусть у нас есть набор обучающих данных \n",
    "{(x,d)}, где x - это различные вектора, а d из множества {+1,-1} указывает к какому классу относится наш вектор.\n",
    "\n",
    "1. Положим вектор весов w равным нулю.\n",
    "\n",
    "2. Повторять N раз следующие шаги:\n",
    "\n",
    "3. Для каждого тестового набора (x,d):\n",
    "\n",
    "4. Вычислить y = sign[(x,w)].\n",
    "\n",
    "5. Если yd < 0, то скорректировать веса w0 = w0 + ad, wi = wi + adxi,  i = 1,2,...,n. \n",
    "\n",
    "Описанный алгоритм довольно легко программировать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Пример\n",
    "\n",
    "Рассмотрим программу обучения персептрона на языке Python. Сначала рассмотрим основной класс персептрона, который умеет учиться по тестовым данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, N):\n",
    "        # Создаем нулевые веса\n",
    "        self.w = list()\n",
    "        for i in range(N):\n",
    "            self.w.append(0)\n",
    "    # метод для вычисления значения персептрона\n",
    "    def calc(self, x):\n",
    "        res = 0\n",
    "        for i in range(len(self.w)):\n",
    "            res = res + self.w[i] * x[i]\n",
    "        return res\n",
    "    # пороговая функция активации персептрона\n",
    "    def sign(self, x):\n",
    "        if self.calc(x) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    # обучение на одном примере\n",
    "    def learn(self, la, x, y):\n",
    "        # обучение только при неверном результате\n",
    "        if y * self.calc(x) <= 0:\n",
    "            for i in range(len(self.w)):\n",
    "                self.w[i] = self.w[i] + la * y * x[i]\n",
    "    # обучение по всем данным Т - кортеж примеров\n",
    "    def learning(self, la, T):\n",
    "        # цикл обучения \n",
    "        for n in range(100):\n",
    "            # обучение по всему набору примеров\n",
    "            for t in T:\n",
    "                self.learn(la, t[0], t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как учится и работает наш персептрон.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.1]\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# создаем класс двумерного персептрона\n",
    "perceptron = Perceptron(2)\n",
    "la = 0.1 # константа обучения\n",
    "# создаем примеры \n",
    "T = list()\n",
    "T.append([[2, 1], 1])\n",
    "T.append([[3, 2], 1])\n",
    "T.append([[4, 1], 1])\n",
    "T.append([[1, 2], -1])\n",
    "T.append([[2, 3], -1])\n",
    "T.append([[5, 7], -1])\n",
    "perceptron.learning(la, T) # обучение персептрона\n",
    "print(perceptron.w)  # печатаем веса\n",
    "# проверим работу на тестовых весах\n",
    "print(perceptron.sign([1.5, 2]))\n",
    "print(perceptron.sign([3, 1.5]))\n",
    "print(perceptron.sign([5, 1]))\n",
    "print(perceptron.sign([5, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что что наш персептрон отлично научился распознавать образы, относя к классу 1 те вектора, у которых первая компонента больше второй, и к классу -1 в противном случае. Хотя устройство персептронов довольно простое эти конструкции могут решать и практические задачи. Кроме того, из таких персептронов состоят нейронные сети.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теоретический материал – Реализация нейронной сети на Python\n",
    "\n",
    "Нейронная сеть — это функциональная единица машинного или глубокого обучения. Она имитирует поведение человеческого мозга, поскольку основана на концепции биологических нейронных сетей.\n",
    "\n",
    "Наиболее распространенный тип нейронной сети, называемый многослойным персептроном (MLP), представляет собой функцию, которая отображает входные данные в выходные данные. MLP имеет один входной слой и один выходной слой. Между ними может быть один или несколько скрытых слоев. Входной слой имеет тот же набор нейронов, что и признаки. Скрытые слои также могут иметь более одного нейрона. Каждый нейрон представляет собой линейную функцию, к которой применяется функция активации для решения сложных задач. Выход каждого слоя подается в качестве входных данных для всех нейронов следующих слоев.\n",
    "\n",
    "Нейронные сети способны решать множество задач. В основном они состоят из таких компонентов:\n",
    "\n",
    "* входной слой (получение и передача данных);\n",
    "\n",
    "* скрытый слой (вычисление);\n",
    "\n",
    "* выходной слой. Чтобы реализовать нейросеть, необходимо понимать, как ведут себя нейроны. Нейрон \n",
    "одновременно принимает несколько входов, обрабатывает эти данные и выдает один выход. Нейронная сеть представляет собой блоки ввода и вывода, где каждое соединение имеет соответствующие веса (это сила связи нейронов; чем вес больше, тем один нейрон сильнее влияет на другой). Данные всех входов умножаются на веса:\n",
    "\n",
    "* x → x*w1;\n",
    "* y → y*w2.\n",
    "\n",
    "Входы после взвешивания суммируются с прибавлением значения порога «c»:\n",
    "xw1 + yw2 + c\n",
    "\n",
    "Полученное значение пропускается через функцию активации (сигмоиду), которая преобразует входы в один выход:\n",
    "\n",
    "z =f(xw1 + yw2 + c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интервал результатов сигмоиды — от 0 до 1. Отрицательные числа стремятся к нулю, а положительные — к единице.\n",
    "\n",
    "Например. Пусть нейрон имеет следующие значения: \n",
    "\n",
    "w = [0,1] c = 4.\n",
    "\n",
    "Входной слой: x = 2, y = 3.\n",
    "\n",
    "\n",
    "((xw1) + (yw2)) + c = 20 + 31 + 4 = 7.\n",
    "z = f(7) = 0.99.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # функция активации f(x) = 1/(1+e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "weights = np.array([0, 1]) #w1 = 0, w2 = 1\n",
    "bias = 4\n",
    "n = Neuron(weights, bias)\n",
    "x = np.array([2, 3]) # x = 2, y = 3\n",
    "print(n.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть состоит из множества соединенных между собой нейронов. Пример несложной нейронной сети\n",
    "\n",
    "![neuralnet1](neuralnet1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
